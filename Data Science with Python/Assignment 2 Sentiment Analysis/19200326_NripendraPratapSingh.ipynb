{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## Extracting Reviews and creating Feedback Detection Model\n",
    "\n",
    "### Nripendra Pratap Singh - 19200326\n",
    "The aim of this assignment is to extract data from the website (http://mlg.ucd.ie/modules/yalp/). For this Assignment, I have chosen 3 categories of businesses:\n",
    "\n",
    "- Restaurants\n",
    "- Gym\n",
    "- Automobile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage_bs(url):\n",
    "    feedback_page = url\n",
    "    page = urlopen(feedback_page)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "weblink = 'http://mlg.ucd.ie/modules/yalp/'\n",
    "soup = get_webpage_bs(weblink)\n",
    "mydivs = soup.findAll(\"div\", {\"class\": \"category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"category\"><h4><a href=\"automotive_list.html\">Category: Automotive</a>  (132 businesses)</h4></div>,\n",
       " <div class=\"category\"><h4><a href=\"cafes_list.html\">Category: Cafes</a>  (96 businesses)</h4></div>,\n",
       " <div class=\"category\"><h4><a href=\"fashion_list.html\">Category: Fashion</a>  (159 businesses)</h4></div>,\n",
       " <div class=\"category\"><h4><a href=\"gym_list.html\">Category: Gym</a>  (122 businesses)</h4></div>,\n",
       " <div class=\"category\"><h4><a href=\"hair_salons_list.html\">Category: Hair and Salons</a>  (143 businesses)</h4></div>,\n",
       " <div class=\"category\"><h4><a href=\"hotels_list.html\">Category: Hotels</a>  (113 businesses)</h4></div>,\n",
       " <div class=\"category\"><h4><a href=\"restaurants_list.html\">Category: Restaurants</a>  (100 businesses)</h4></div>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydivs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creatiing Empty Dataframes to store data from the websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto = pd.DataFrame(columns=['review', 'label'])\n",
    "df_gym = pd.DataFrame(columns=['review', 'label'])\n",
    "df_resto = pd.DataFrame(columns=['review', 'label'])\n",
    "english_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions that will be used in the Program throughout the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Webpage data extraction program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_df(weblink, url_category):\n",
    "    df_temp = pd.DataFrame(columns=['review', 'label'])\n",
    "    category_sites = get_webpage_bs(url_category)\n",
    "    #print(category_sites)\n",
    "    for link in category_sites.find_all('a', href=True):\n",
    "        #print(link.text)\n",
    "        curr_company = get_webpage_bs(weblink+link['href'])\n",
    "        info = curr_company.findAll(\"div\", {\"class\": \"review\"})\n",
    "        for curr_info in info:\n",
    "            rating = curr_info.select(\"p:nth-of-type(2)\")\n",
    "            review = curr_info.select(\"p:nth-of-type(3)\")\n",
    "            rating = int(rating[0].img.get('alt').split('-')[0].strip())\n",
    "            rating = \"positive\" if rating > 3 else \"negative\"\n",
    "            review = preprocess_reviews(review[0].text)\n",
    "            new_row = pd.Series({'review': review, 'label': rating})\n",
    "            df_temp = df_temp.append(new_row, ignore_index = True)\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Preprocessing Section\n",
    "This section is responsible to preprocess each review before being sent to the csv backup which would later be used to run our model upon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocess_reviews function takes in a review, removes all the punctutations, and sends the review for further preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews(line):\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    line = REPLACE_NO_SPACE.sub(\"\", line.lower())\n",
    "    line = get_stemmed_text(remove_stop_words(line))\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Stop Words\n",
    "This Function is responsible to remove all the words that do not provide or define meaning of the sentence. These words are used to frame the sentence, however, their presence or absence do not affect the overall meaning of the statement. \n",
    "\n",
    "For ex: \"somewhere, there is a cat\", here, \"somewhere\" and \"cat\" only provide meaning to sentence and words like 'there', \"is\" and 'a' are the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(review):\n",
    "    removed_stop_words = []\n",
    "    removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    removed_stop_words = ' '.join(w for w in removed_stop_words)\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Porter Stemmer\n",
    "This is a process wherein the word is reduced to its stem or base form, which helps the system to remove the variations of many words that may have arised due to it's usage in the context, however, once reduced to it's root, it makes it easier for the system to understand their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_text(review):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    return ' '.join([stemmer.stem(word) for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Backup Creation\n",
    "This section reads the data from the CSV files and if the data is not present, only then it focuses on extracting the same from the website. Since website creawling is an expensive operation, it helps if we already have data in a backup which we can directly read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data_backup'):\n",
    "    os.makedirs('data_backup')\n",
    "    flg = False\n",
    "exists_auto = os.path.isfile('data_backup/df_auto.csv')\n",
    "exists_gym = os.path.isfile('data_backup/df_gym.csv')\n",
    "exists_resto = os.path.isfile('data_backup/df_resto.csv')\n",
    "if exists_auto:\n",
    "    df_auto = pd.read_csv('data_backup/df_auto.csv')\n",
    "    auto = False\n",
    "else:\n",
    "    auto = True\n",
    "if exists_gym:\n",
    "    df_gym = pd.read_csv('data_backup/df_gym.csv')\n",
    "    gym = False\n",
    "else:\n",
    "    gym = True\n",
    "if exists_resto:\n",
    "    df_resto = pd.read_csv('data_backup/df_resto.csv')\n",
    "    resto = False\n",
    "else:\n",
    "    resto = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_id in mydivs:\n",
    "    if 'Automotive' in curr_id.text and auto :\n",
    "        url_category = weblink + curr_id.a.get('href')\n",
    "        df_auto = get_data_df(weblink, url_category)\n",
    "        df_auto.to_csv('data_backup/df_auto.csv', index=False)\n",
    "    if 'Gym' in curr_id.text and gym:\n",
    "        url_category = weblink + curr_id.a.get('href')\n",
    "        df_gym = get_data_df(weblink, url_category)\n",
    "        df_gym.to_csv('data_backup/df_gym.csv', index=False)\n",
    "    if 'Restaurants' in curr_id.text and resto:\n",
    "        url_category = weblink + curr_id.a.get('href')\n",
    "        df_resto = get_data_df(weblink, url_category)\n",
    "        df_resto.to_csv('data_backup/df_resto.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>man work tonight 8-12-17 rude real jerk need h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chri rude person gave attitud chang peopl go w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>one favorit ga station stop store alway clean ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>oh thank heaven seven eleven dont know thank s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>five star guy work weekday morn around 8-9am-i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review     label\n",
       "0  man work tonight 8-12-17 rude real jerk need h...  negative\n",
       "1  chri rude person gave attitud chang peopl go w...  negative\n",
       "2  one favorit ga station stop store alway clean ...  positive\n",
       "3  oh thank heaven seven eleven dont know thank s...  negative\n",
       "4  five star guy work weekday morn around 8-9am-i...  positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>your look box east valley highli recommend gym...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>realli excit tri fun workout routin would also...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>interest take box bootcamp class research foun...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>work 1 1 box bout 6 month love price reason al...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>place liter kick butt everi singl time actual ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review     label\n",
       "0  your look box east valley highli recommend gym...  positive\n",
       "1  realli excit tri fun workout routin would also...  negative\n",
       "2  interest take box bootcamp class research foun...  negative\n",
       "3  work 1 1 box bout 6 month love price reason al...  positive\n",
       "4  place liter kick butt everi singl time actual ...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gym.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>husband rare afternoon decid tri place friend ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>year thought wine store sister stop told go ni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>place charm went husband love simpl clean deco...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>want tri place coupl year final stop last nigh...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>decor look ok layout busi difficult walk sit/t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review     label\n",
       "0  husband rare afternoon decid tri place friend ...  negative\n",
       "1  year thought wine store sister stop told go ni...  positive\n",
       "2  place charm went husband love simpl clean deco...  positive\n",
       "3  want tri place coupl year final stop last nigh...  positive\n",
       "4  decor look ok layout busi difficult walk sit/t...  negative"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been preprocessed, we need to convert the data into numeric values that could be understood by the Machine Learning Algorithm we are going to use to predict the class labels of the reviews. \n",
    "\n",
    "In this assignment's case, we are going to use TF-IDF Vectoriser. The TF-IDF or Term Frequency - Inverse Document Frequency is used to determine how important a word is in the document the TFIDF is being run upon. If the word appears to be most important, the TF-IDF rating of the word is going to be 1, and 0 in case otherwise. \n",
    "\n",
    "In the below run of the TFIDF Vectoriser, we have limited the number of words or features to 2500 in order to:\n",
    "- Have similar number of features across models to enable cross validation between categories\n",
    "- words beyond top 2500 are lesser important words and their absence would not make a great difference to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running TFIDF Vectoriser over the Data in the Category Automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.626\n",
      "Accuracy for C=0.05: 0.64\n",
      "Accuracy for C=0.25: 0.852\n",
      "Accuracy for C=0.5: 0.884\n",
      "Accuracy for C=1: 0.908\n",
      "Final Accuracy: 0.895\n",
      "             negative positive \n",
      "    negative    594.0    194.0 \n",
      "    positive     16.0   1196.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = 2500)\n",
    "tfidf_vectorizer.fit(df_auto['review'])\n",
    "X_auto = tfidf_vectorizer.transform(df_auto['review'])\n",
    "X_test_auto = tfidf_vectorizer.transform(df_auto['review'])\n",
    "\n",
    "#Splitting Data into Train Test and Validation Test Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_auto, df_auto['label'], train_size = 0.75) \n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "# Final Model comprising of the entire data\n",
    "final_tfidf_auto = LogisticRegression(C=0.2)\n",
    "final_tfidf_auto.fit(X_auto, df_auto['label'])\n",
    "\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(df_auto['label'], final_tfidf_auto.predict(X_test_auto)))\n",
    "\n",
    "print_cm(confusion_matrix(df_auto['label'], final_tfidf_auto.predict(X_test_auto)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above run, we also tried to figure out the performance of Logistic Regression over the models and tried to vary the inverse of regularisation paramter from 0.01 to 1. The Regularisation Parameter helps us to prevent overfitting which is done by heavily penalising on the errors. Here 1 means least penalty. \n",
    "\n",
    "We have also set the final value of C as 0.2 to avoid overfitting, but also to avoid underfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running TFIDF Vectoriser over the Data in the Category Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.628\n",
      "Accuracy for C=0.05: 0.646\n",
      "Accuracy for C=0.25: 0.808\n",
      "Accuracy for C=0.5: 0.856\n",
      "Accuracy for C=1: 0.876\n",
      "Final Accuracy: 0.8615\n",
      "             negative positive \n",
      "    negative    433.0    268.0 \n",
      "    positive      9.0   1290.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = 2500)\n",
    "tfidf_vectorizer.fit(df_gym['review'])\n",
    "X_gym = tfidf_vectorizer.transform(df_gym['review'])\n",
    "X_test_gym = tfidf_vectorizer.transform(df_gym['review'])\n",
    "\n",
    "#Splitting Data into Train Test and Validation Test Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_gym, df_gym['label'], train_size = 0.75) \n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "final_tfidf_gym = LogisticRegression(C=0.2)\n",
    "final_tfidf_gym.fit(X_gym, df_gym['label'])\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(df_gym['label'], final_tfidf_gym.predict(X_test_gym)))\n",
    "\n",
    "print_cm(confusion_matrix(df_gym['label'], final_tfidf_gym.predict(X_test_gym)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running TFIDF Vectoriser over the Data in the Category Automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.564\n",
      "Accuracy for C=0.05: 0.6\n",
      "Accuracy for C=0.25: 0.82\n",
      "Accuracy for C=0.5: 0.862\n",
      "Accuracy for C=1: 0.864\n",
      "Final Accuracy: 0.868\n",
      "             negative positive \n",
      "    negative    597.0    241.0 \n",
      "    positive     23.0   1139.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = 2500)\n",
    "tfidf_vectorizer.fit(df_resto['review'])\n",
    "X_resto = tfidf_vectorizer.transform(df_resto['review'])\n",
    "X_test_resto = tfidf_vectorizer.transform(df_resto['review'])\n",
    "\n",
    "#Splitting Data into Train Test and Validation Test Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resto, df_resto['label'], train_size = 0.75) \n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "    \n",
    "final_tfidf_resto = LogisticRegression(C=0.2)\n",
    "final_tfidf_resto.fit(X_resto, df_resto['label'])\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(df_resto['label'], final_tfidf_resto.predict(X_test_resto)))\n",
    "\n",
    "\n",
    "print_cm(confusion_matrix(df_resto['label'], final_tfidf_resto.predict(X_test_resto)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to supplement our research on the accuracy being gained by the Logistic Regression model, I thought of performing a Naive Bayes Classification to see how does it impact our Training Model and their Precision Measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.02, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_auto = BernoulliNB(alpha=0.02)\n",
    "NB_auto.fit(X_auto, df_auto['label'])\n",
    "\n",
    "NB_gym = BernoulliNB(alpha=0.02)\n",
    "NB_gym.fit(X_gym, df_gym['label'])\n",
    "\n",
    "NB_resto = BernoulliNB(alpha=0.02)\n",
    "NB_resto.fit(X_resto, df_resto['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above Tests we can conclude that:\n",
    "- Logistic Regression was chosen as an algorithm to train the model and it's performance was analysed. \n",
    "- The Logistic Regression returned values with high accuracy nearing 90% with C = 0.2, false negatives were very less however, false positives were seen to be higher in number. \n",
    "- As Mental Accounting states, if a review is classified as negative if it was actually positive, it would be more harmful to the business, than a negative review being classed as Positive. When this happens, the customer can still go through other reviews and determine the overall effectiveness of a business. However, a negative-labelled feedback weighs more heavily on the customer than a positive one. \n",
    "- with the above theory in mind, we can assess the confusion matrix and see that not only does the model classify reviews mostly appropriately, it also has neglible false negatives (positive review classified as negative), thus we can accept this model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automobile Classifer Model\n",
    "Model trained on Automobile, run on restaurant and gym data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Running on Gym Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.6515\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_gym['label'], final_tfidf_auto.predict(X_test_gym)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative     18.0    683.0 \n",
      "    positive     14.0   1285.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_gym['label'], final_tfidf_auto.predict(X_test_gym)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04911323328785812"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_gym['label'], final_tfidf_auto.predict(X_test_gym), pos_label=\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(df_gym['label'], final_tfidf_auto.predict(X_test_gym), pos_label=\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on Restaurant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.581\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_resto['label'], final_tfidf_auto.predict(X_test_resto)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative     15.0    823.0 \n",
      "    positive     15.0   1147.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_resto['label'], final_tfidf_auto.predict(X_test_resto)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.545\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_resto['label'], NB_auto.predict(X_test_resto)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.5285\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_gym['label'], NB_auto.predict(X_test_gym)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative    390.0    311.0 \n",
      "    positive    632.0    667.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_gym['label'], NB_auto.predict(X_test_gym)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4526987811955891"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_gym['label'], NB_auto.predict(X_test_gym), pos_label=\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above runs of Naive Bayes and Logistic Regression, we observe that Logistic Regression Produces better accuracy, but suffers from Low F1 score, whereas, Naive Bayers produces lower accuracy, but leads to higher F1 Score\n",
    "\n",
    "When we are dealing with reviews, which is the case in our assignment, if the review is being classified as Positive, when it is indeed negative or vice versa, it does not do a significant damage. For example, if this was a cancer prediction model that were to predict if a patient has cancer or not, classifying someone who has cancer as cancer-free would lead to real life implications. In such cases, where False Positives and False Negatives play an important role, we need to depend a lot on increasing the value of Precision, Recall and F1 Score. \n",
    "\n",
    "In our case, since false positive and False negative do not play a significant role, we do not need to focus on getting higher values in Precision, Recall and F1 score. We can only focus upon increasing the accuracy of the model.\n",
    "\n",
    "This observation of mine lead to me making a decision to go ahead with Logistic Regression for this case study as Naive Bayes did provide a significantly increase F1 Score, however, it did not help with the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.6045\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_auto['label'], final_tfidf_gym.predict(X_test_auto)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.5815\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_resto['label'], final_tfidf_gym.predict(X_test_resto)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix\n",
    "Confusion Matrix for Gym_Model on Automobile Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative      2.0    786.0 \n",
      "    positive      5.0   1207.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_auto['label'], final_tfidf_gym.predict(X_test_auto)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix for Restaurant_Model on Automobile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative      5.0    833.0 \n",
      "    positive      4.0   1158.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_resto['label'], final_tfidf_gym.predict(X_test_resto)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resto Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.603\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_auto['label'], final_tfidf_resto.predict(X_test_auto)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.6475\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Accuracy: %s\" % accuracy_score(df_gym['label'], final_tfidf_resto.predict(X_test_gym)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix\n",
    "Confusion Matrix for Gym_Model on Automobile Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative     71.0    717.0 \n",
      "    positive     77.0   1135.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_auto['label'], final_tfidf_resto.predict(X_test_auto)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix for Gym_Model on Automobile Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             negative positive \n",
      "    negative     24.0    677.0 \n",
      "    positive     28.0   1271.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix(df_gym['label'], final_tfidf_resto.predict(X_test_gym)),labels = ['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above experiment we can see that:\n",
    "- why we chose Logistic Regression over Naive Bayes, this was because the current case study warranted a more accuracy based approach rather than focusing on Precision and Recall\n",
    "- The Logistic Regression was able to correctly identify the True Positive, but failed to work on True Negative and classified most of them as Positives. This can be due to the fact that the reviews from each of the categories are cateogry dependent and often use terms that are relevant to those categories, thus this makes using context from one category in training set and testing it on other set less feasible. \n",
    "- From category dependent Logistic Regression Models we can see that the predictor works well with better scores in True Positives and True Negative, but fails to replicate similar results when running through cross category data. This further strengthens our findings that reviews from category A won't be a suitable data for predicting reviews from Category B as they do not have any inter-relatibility between the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
